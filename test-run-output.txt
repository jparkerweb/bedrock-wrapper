
> bedrock-wrapper@2.8.0 test
> node test-models.js --both --converse


     ___         _                 _     _ _ _                               
    | . > ___  _| | _ _  ___  ___ | |__ | | | | _ _  ___  ___  ___  ___  _ _ 
    | . \/ ._>/ . || '_>/ . \/ | '| / / | | | || '_><_> || . \| . \/ ._>| '_>
    |___/\___.\___||_|  \___/\_|_.|_\_\ |__/_/ |_|  <___||  _/|  _/\___.|_|  
                                                         |_|  |_|            
    
[dotenv@17.2.3] injecting env (5) from .env -- tip: ‚úÖ audit secrets and track compliance: https://dotenvx.com/ops
Model Test Usage:
  npm run test                  # Test with Invoke API (default)
  npm run test -- --converse       # Test with Converse API only
  npm run test -- --both           # Test both APIs and compare


‚Ñπ Starting tests with 57 models using Both APIs (Comparison)...
‚Ñπ Each model will be tested with streaming and non-streaming calls


------------------------------------------------------------
Testing Claude-4-5-Opus ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "global.anthropic.claude-opus-4-5-20251101-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "global.anthropic.claude-opus-4-5-20251101-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 2882
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "2cd8c654-64e4-4e5a-93e4-61b9247ad0b9",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-4-5-Opus

----------------------------------------

------------------------------------------------------------
Testing Claude-4-5-Opus-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The user is asking me to respond with exactly one word to answer what 1+1 is.

1+1 = 2

So I should respond with just: Two</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>The user is asking a simple math question: What is 1+1? They want exactly one word as a response.

1+1 = 2

So I should respond with just "Two" or "2". Since they asked for one word, "Two" would be the word form of the answer.</think>

Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "global.anthropic.claude-opus-4-5-20251101-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "global.anthropic.claude-opus-4-5-20251101-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user is asking a simple math question: What is 1+1? They want exactly one word as a response.\n\n1+1 = 2\n\nThe answer is \"Two\"",
              "signature": "EqoCCkgIChABGAIqQJoMXtw69ssunmOGw/epm71pOrTtVeaPIsm/DPXLhektE6L7IqissmTahsJBkLXztlULewVCHe+GV+5AG2Gc1WwSDOK6tWRax5bTZHWVjRoMD/4IIuNQ/8eiUnW7IjCYiklH7onwE7YWNT4X/mXK04EwJKQzfUmllbnSQnK2Tr2EKtSmWNXerGh5FP57YA4qjwHMa9nzibhnRVWBPkbWohwOQ/TMgYDz+n41/CXMSjIW633KoYuvN5v+3hsMXXnClP/mjMH42mM/icjKo0A1xzImaW6PA6x4Ok3XtQvUFmJNHT6KCOgZvKSXluEoKxQoKBdG9Z82Bu6qO/bMDKfKBeJVQY/beSg0ZcjbQHn6ucBNIatiqhzyXVgIgwNN8mHpQBgB"
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 50,
    "outputTokens": 52,
    "totalTokens": 102,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 2373
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "858956bb-6dff-441a-9e13-a4cd2cb09f8e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The user is asking a simple math question: What is 1+1? They want exactly one word as a response.

1+1 = 2

The answer is "Two"</think>

Two"
‚úì üîç Both APIs successful for Claude-4-5-Opus-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-4-1-Opus ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-1-20250805-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-1-20250805-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 4646
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "faacac82-5db1-4237-b8df-6e4fd29df54d",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-4-1-Opus

----------------------------------------

------------------------------------------------------------
Testing Claude-4-1-Opus-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The user is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2, which is one word, so I should respond with "Two".</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>The user is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2. Since they want exactly one word, I should just say "Two" or "2". "Two" would be the word form, so I'll go with that.</think>

Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-1-20250805-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-1-20250805-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user is asking me to respond with exactly one word to the question \"What is 1+1?\". The answer to 1+1 is 2, which is one word, so I should respond with \"Two\".",
              "signature": "EswCCkgIChABGAIqQD0pMKprELBshtGQlTktSJv/IL74Mdx2dcxfr0OPUErUdwSon961admeqKlo0BwC9sRJVwAYkdEbCjvTcAm42GoSDI/9Vvty7JFiL592tBoMeJsBzNjjHcm56WyPIjDi21XrIWuAAH4IV2v8KGYH+NtBtf0Jsqw4X8TwzBVBjHKBLVybrfObobHPXIb4T90qsQGiau9qmUp5C1LCqY+e/XFdotN7lfsxfeiD1mOeOIWSI3lk6xQlZjQwf/NiIzijgfU/uWK7OMDGyNVxIXdcaJ3CLIikMVEsxHECnhxop28voCccvSSFn3nyyzppdknKHMaf0KC95O1JseshxePcrWHcjZebBuRauLknJgkU/PYmIwlM+5kUUrrqnRhcFucKsXbSXD9ot/CTF/q3KcND2RgYsNIuHMvq1AviqiXzEtX367oYAQ=="
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 49,
    "outputTokens": 61,
    "totalTokens": 110,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 6548
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "10fa1c38-bca5-4303-b725-112e363bce7b",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The user is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2, which is one word, so I should respond with "Two".</think>

Two"
‚úì üîç Both APIs successful for Claude-4-1-Opus-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-4-Opus ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 4334
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "f75147ca-4154-48ba-aee0-fa07fc265ad6",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-4-Opus

----------------------------------------

------------------------------------------------------------
Testing Claude-4-Opus-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The human is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2. I need to respond with just that one word.</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>The user is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2, which is already one word. So I should respond with "Two" or "2". Since they asked for a word, "Two" would be more appropriate than the numeral "2".</think>

Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-opus-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The human is asking me to respond with exactly one word to the question \"What is 1+1?\". The answer to 1+1 is 2, which is conveniently one word. So I should respond with just \"Two\".",
              "signature": "Et8CCkgIChABGAIqQA8ygbwpCTPM/I9T8T9OYhPkUMsxGLGkS9GsifOAtPernH3o7YqR7YCVGiCGtdep8G0zu5UmGPR10XWZoH1rGnESDDKcHIFx4VOviLSEaBoMwOoFySsLSI/VF/WFIjDUIHhIgWUEcfzZYS9yN/Gq9EwnWAYdFQEMjVg9IfGzBSCyWEaI6P6X9Iz2X18IQjUqxAGK074J1h1zBmfpOcE/mufq0ZVOn/NxqSzOMQzhM/0QFra/jGG8AA/G4wT5wN5fVHTVQvhMrf+8Qm1TagBJD8+J/2WqyexrFLmk5VC9fwYNz3QzGm3cKPXfGb2/DazjFj7m9OBpocBJLxzjNvBpeptWgSuQ2y4OfpToMNLeRgPNNUvlFmIXe5ZZQ90OidGuWVuF4V7RDRmXr3hxHHkeK0ZwpvTxDUucIDEdbvsd0wC2dZ653gSCrJCyniZaW3Nq1iTS1XC3GAE="
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 49,
    "outputTokens": 65,
    "totalTokens": 114,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 7328
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "f1fce613-bb05-4237-8b28-1ddb15182d9e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The human is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2, which is conveniently one word. So I should respond with just "Two".</think>

Two"
‚úì üîç Both APIs successful for Claude-4-Opus-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-4-5-Sonnet ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 1781
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "b9a24a23-2367-466d-b4a3-f3c594d51224",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-4-5-Sonnet

----------------------------------------

------------------------------------------------------------
Testing Claude-4-5-Sonnet-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The user is asking for a simple math problem: 1+1=2

They want me to respond with exactly one word. The answer to 1+1 is 2, which I can express as the word "Two".</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>The user is asking me what 1+1 is, and they want me to respond with exactly one word.

1+1 = 2

So I should respond with: Two</think>

Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-5-20250929-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user is asking me what 1+1 is, and they want me to respond with exactly one word.\n\n1+1 = 2\n\nSo I should respond with just: Two",
              "signature": "Eq0CCkgIChABGAIqQADRpwULY8FpICzc+26ELfpmbD8FtZTBGws7ejyR7yx288kvmMVcEM8cSJZ9sTQEOkh1VqmrOC/Jgtl2uRAPbVgSDO9/tF2wZlLiM6J7VxoMzSqFwllxJDey5o2bIjDHinpOPvI6/mm3lvTpa+ZW5knA0gpNvqxre8qOqBlMoArBs+artO2R+milT0LPCUUqkgF6Pzc9s68jYGH1tStmKi0WbcS5wTbAZ54AmznmazLCotQaZ/P9ko+g+8qpWrraYA6Z90wP+bCX+EeN8ZMNT1+VJs2pAP/RXMOEVhUBEpqO4zHgtsNRWFiYCKCAsX+D49I/pijneoQqe1hGKd8zwzpB5kQBSFpIyImAISR3+CJ+cRzw0xHfjF/NuKj5WPIn1HYh0BgB"
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 49,
    "outputTokens": 54,
    "totalTokens": 103,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 2332
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "aafcdde8-c019-497a-b2d9-e5470404f176",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The user is asking me what 1+1 is, and they want me to respond with exactly one word.

1+1 = 2

So I should respond with just: Two</think>

Two"
‚úì üîç Both APIs successful for Claude-4-5-Sonnet-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-4-5-Haiku ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úó ‚úó Invoke API Streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úó ‚úó Invoke API Non-streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.

Converse API request: {
  "modelId": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Non-streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.
‚úó ‚ùå Both APIs failed for Claude-4-5-Haiku

----------------------------------------

------------------------------------------------------------
Testing Claude-4-5-Haiku-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úó ‚úó Invoke API Streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úó ‚úó Invoke API Non-streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úó ‚úó Converse API Streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.

Converse API request: {
  "modelId": "us.anthropic.claude-haiku-4-5-20251001-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úó ‚úó Converse API Non-streaming: Model access is denied due to IAM user or service role is not authorized to perform the required AWS Marketplace actions (aws-marketplace:ViewSubscriptions, aws-marketplace:Subscribe) to enable access to this model. Refer to the Amazon Bedrock documentation for further details. Your AWS Marketplace subscription for this model cannot be completed at this time. If you recently fixed this issue, try again after 15 minutes.
‚úó ‚ùå Both APIs failed for Claude-4-5-Haiku-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-4-Sonnet ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 673
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "7d7a37cc-7024-465f-926f-e06b3330157a",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-4-Sonnet

----------------------------------------

------------------------------------------------------------
Testing Claude-4-Sonnet-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The user is asking for the sum of 1+1, which is 2. They've specifically requested that I respond with exactly one word. The answer to 1+1 is 2, and "Two" would be one word.</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>The user is asking for the answer to 1+1, but they want me to respond with exactly one word. The answer to 1+1 is 2, which can be written as the word "two".</think>

Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-sonnet-4-20250514-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The human is asking me to respond with exactly one word to the question \"What is 1+1?\". The answer to 1+1 is 2. The word \"two\" represents this answer, so I should respond with \"Two\".",
              "signature": "EuECCkgIChABGAIqQDdwtFlZDeWbW+v7W3VBZY3A0uL/icnfSaRnBvhqtYZUXItKub/Qa2wyubdvzksKAkFfcrNAqt/DjLhpj2hcx3ISDKDgX0Iip6bewQ4IgBoMM4vbJpXK2nCrrpKWIjCMWHtDrKMwp14A0jVxRd06ZwUEumWxxf757AV6ZslgY6Z1lVY1qDr+SMuQP3fwB60qxgH9MbL0d8D6FK3FONrtmGPmcGGPRzYEcblsEyLswyAv7Ohx4paC0OJeCzTC59uXRAvgUUbhBvUhfSVTWGKBC8HU0GBRJAwC7CyCTS+EQ2N6bkLR5CqFtBSxAPc54AgMccJA1HalZJrsNq+UJaVLH43E0e/FkCPXg8Yf/rbvKjjDTtMST7sir38tq/LPzNdxL8snBvcVX5INwsLJttHLtJsgTbbGVy3YP+FoSNFEiQkJ+psHVrt9sRXN3JnqjqsIsYFeEHf1pGAYAQ=="
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 49,
    "outputTokens": 65,
    "totalTokens": 114,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 1261
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "43ed9836-473a-4b3e-818a-8a3ab5f9d705",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The human is asking me to respond with exactly one word to the question "What is 1+1?". The answer to 1+1 is 2. The word "two" represents this answer, so I should respond with "Two".</think>

Two"
‚úì üîç Both APIs successful for Claude-4-Sonnet-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-3-7-Sonnet-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Streaming: "<think>The question asks for exactly one word response to "What is 1+1?". The answer to 1+1 is 2, and "2" is a single word (technically a numeral), so I should respond with just "2".</think>

Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 1228,
  "temperature": 1,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ],
  "thinking": {
    "type": "enabled",
    "budget_tokens": 1024
  }
}
‚úì ‚úì Invoke API Non-streaming: "<think>I need to answer this question with exactly one word. The question asks for 1+1, which equals 2. So my answer should simply be "2".</think>

2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 1228,
    "temperature": 1
  },
  "additionalModelRequestFields": {
    "thinking": {
      "type": "enabled",
      "budget_tokens": 1024
    },
    "anthropic_beta": [
      "output-128k-2025-02-19"
    ]
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The question asks for exactly one word. It's asking what 1+1 is, which equals 2. The answer \"2\" is one word, so I should respond with just \"2\".",
              "signature": "ErcBCkgIChABGAIiQPywJnvyKdaFvxCfZX0Bq2D6MZlvm5d3EGmhv3vcsUNNky8MVIHZnnhzbMETnwVrNaiACoUeJ3ZidOViWS8s1XUSDFKb3LPIgEvC7u+E1RoMIpcXW/BV7+HM0YmgIjDIFOQQqnFtPtMVKuZ06aE/kFPamcHYnT0vrQDyduqSdvOcWvqvES31a3AgPQZKEksqHQxkGcGBlQdh+Am8V7uK6No/JNdU8vksslBePHN/GAI="
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 49,
    "outputTokens": 55,
    "totalTokens": 104,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 1811
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "e55c6fd1-600e-40d8-a707-4ab60619341e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "<think>The question asks for exactly one word. It's asking what 1+1 is, which equals 2. The answer "2" is one word, so I should respond with just "2".</think>

Two"
‚úì üîç Both APIs successful for Claude-3-7-Sonnet-Thinking

----------------------------------------

------------------------------------------------------------
Testing Claude-3-7-Sonnet ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31",
  "anthropic_beta": [
    "output-128k-2025-02-19"
  ]
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 547
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "03f8f978-7f9e-48b6-82c6-01a7b629087e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-3-7-Sonnet

----------------------------------------

------------------------------------------------------------
Testing Claude-3-5-Sonnet-v2 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Streaming: "two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Non-streaming: "two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "two"

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-sonnet-20241022-v2:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25
  },
  "metrics": {
    "latencyMs": 863
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "892d9cfb-e082-407a-9be2-a602c7cf7f24",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "two"
‚úì üîç Both APIs successful for Claude-3-5-Sonnet-v2

----------------------------------------

------------------------------------------------------------
Testing Claude-3-5-Sonnet ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-sonnet-20240620-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25
  },
  "metrics": {
    "latencyMs": 584
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "c7ea42b1-e233-48d6-b93e-a863835fdcf3",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-3-5-Sonnet

----------------------------------------

------------------------------------------------------------
Testing Claude-3-5-Haiku ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.anthropic.claude-3-5-haiku-20241022-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 4,
    "totalTokens": 25,
    "cacheReadInputTokens": 0,
    "cacheWriteInputTokens": 0
  },
  "metrics": {
    "latencyMs": 584
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "3fdb7591-e778-4f5d-afe3-f8ae8093c2b4",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Claude-3-5-Haiku

----------------------------------------

------------------------------------------------------------
Testing Claude-3-Haiku ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2,
  "anthropic_version": "bedrock-2023-05-31"
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.anthropic.claude-3-haiku-20240307-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.anthropic.claude-3-haiku-20240307-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 5,
    "totalTokens": 26
  },
  "metrics": {
    "latencyMs": 354
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "1eacdb85-068c-41f9-b7ff-fdb7d1eaf7fd",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Claude-3-Haiku

----------------------------------------

------------------------------------------------------------
Testing Llama-3-3-70b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-3-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-3-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 48,
    "outputTokens": 3,
    "totalTokens": 51
  },
  "metrics": {
    "latencyMs": 198
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "3ab2fa92-fa55-414a-9b09-89d5402462b9",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-3-70b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-2-1b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-2-1b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-2-1b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 48,
    "outputTokens": 3,
    "totalTokens": 51
  },
  "metrics": {
    "latencyMs": 161
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "bfd2cbf9-3304-428e-93a2-0cc6b6e53992",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-2-1b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-2-3b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-2-3b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2."

Converse API request: {
  "modelId": "us.meta.llama3-2-3b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "2."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 48,
    "outputTokens": 3,
    "totalTokens": 51
  },
  "metrics": {
    "latencyMs": 222
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "c64148f4-3e41-434a-94d7-8b25c26929f1",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2."
‚úì üîç Both APIs successful for Llama-3-2-3b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-2-11b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-2-11b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-2-11b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 48,
    "outputTokens": 3,
    "totalTokens": 51
  },
  "metrics": {
    "latencyMs": 134
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "c0c91712-a83d-4b8b-a057-e3019ffc465c",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-2-11b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-2-90b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-2-90b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-2-90b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 48,
    "outputTokens": 3,
    "totalTokens": 51
  },
  "metrics": {
    "latencyMs": 237
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "61f5ddcf-3aeb-43ad-babe-e98dc095ef88",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-2-90b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-1-8b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-1-8b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-1-8b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "\n\nTwo."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 28,
    "outputTokens": 4,
    "totalTokens": 32
  },
  "metrics": {
    "latencyMs": 128
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "c9db37c8-a2cf-4798-9ed1-3c02a267496e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-1-8b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-1-70b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-1-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "us.meta.llama3-1-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "\n\nTwo."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 27,
    "outputTokens": 4,
    "totalTokens": 31
  },
  "metrics": {
    "latencyMs": 435
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "808ee705-3514-4b19-88e6-97314c803ccf",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Llama-3-1-70b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-1-405b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: The provided model identifier is invalid.

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: The provided model identifier is invalid.
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.meta.llama3-1-405b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Streaming: The provided model identifier is invalid.

Converse API request: {
  "modelId": "us.meta.llama3-1-405b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Non-streaming: The provided model identifier is invalid.
‚úó ‚ùå Both APIs failed for Llama-3-1-405b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-8b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "meta.llama3-8b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "meta.llama3-8b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "\n\nTwo"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 27,
    "outputTokens": 3,
    "totalTokens": 30
  },
  "metrics": {
    "latencyMs": 128
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "de1ca566-c6bd-47dd-bba2-0f689ae7477e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Llama-3-8b

----------------------------------------

------------------------------------------------------------
Testing Llama-3-70b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <|begin_of_text|>
<|start_header_id|>user<|end_header_id|>
Respond with exactly one word: What is 1+1?
<|eot_id|>
<|start_header_id|>assistant<|end_header_id|>


Final request: {
  "prompt": "<|begin_of_text|>\n<|start_header_id|>user<|end_header_id|>\nRespond with exactly one word: What is 1+1?\n<|eot_id|>\n<|start_header_id|>assistant<|end_header_id|>\n",
  "max_gen_len": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "meta.llama3-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "meta.llama3-70b-instruct-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "\n\nTwo"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 27,
    "outputTokens": 3,
    "totalTokens": 30
  },
  "metrics": {
    "latencyMs": 190
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "11d5b719-f12d-47da-bed8-2700daeb2c52",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Llama-3-70b

----------------------------------------

------------------------------------------------------------
Testing Nova-Pro ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.amazon.nova-pro-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "us.amazon.nova-pro-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 13,
    "outputTokens": 2,
    "totalTokens": 15
  },
  "metrics": {
    "latencyMs": 250
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "c8cbf71c-002c-401f-bcd2-f6534d75e61f",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"
‚úì üîç Both APIs successful for Nova-Pro

----------------------------------------

------------------------------------------------------------
Testing Nova-Lite ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.amazon.nova-lite-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.amazon.nova-lite-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 13,
    "outputTokens": 1,
    "totalTokens": 14
  },
  "metrics": {
    "latencyMs": 276
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "3116c188-7b6e-48b9-bc79-e645e23ec425",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Nova-Lite

----------------------------------------

------------------------------------------------------------
Testing Nova-2-Lite ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Streaming: "2."

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Non-streaming: "2."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.amazon.nova-2-lite-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2."

Converse API request: {
  "modelId": "us.amazon.nova-2-lite-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "2."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 59,
    "outputTokens": 3,
    "totalTokens": 62
  },
  "metrics": {
    "latencyMs": 312
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "1e2ebb0b-2c03-468c-bc86-b6a1005c562e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2."
‚úì üîç Both APIs successful for Nova-2-Lite

----------------------------------------

------------------------------------------------------------
Testing Nova-Micro ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  },
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ]
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "schemaVersion": "messages-v1",
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  },
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    },
    {
      "role": "assistant",
      "content": [
        {
          "text": ""
        }
      ]
    }
  ]
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.amazon.nova-micro-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "us.amazon.nova-micro-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 13,
    "outputTokens": 1,
    "totalTokens": 14
  },
  "metrics": {
    "latencyMs": 268
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "6e744740-e88f-44e0-9448-a85509ca1a3b",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Nova-Micro

----------------------------------------

------------------------------------------------------------
Testing GPT-OSS-120B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "openai.gpt-oss-120b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user asks: \"Respond with exactly one word: What is 1+1?\" They want a one-word answer. The answer is \"two\". That's one word. So respond with \"two\"."
            }
          }
        },
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 52,
    "totalTokens": 134
  },
  "metrics": {
    "latencyMs": 562
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "20cb1c36-0bfc-4548-827c-bd2dc10b8194",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Streaming: "two"

Converse API request: {
  "modelId": "openai.gpt-oss-120b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user asks: \"Respond with exactly one word: What is 1+1?\" They want a one-word answer. The answer is \"Two\". That's one word. So respond with \"Two\"."
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 52,
    "totalTokens": 134
  },
  "metrics": {
    "latencyMs": 533
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "41557462-535c-4f31-8620-f61a1918f135",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for GPT-OSS-120B

----------------------------------------

------------------------------------------------------------
Testing GPT-OSS-20B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "openai.gpt-oss-20b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user says: \"Respond with exactly one word: What is 1+1?\" So the answer should be a single word. The sum is 2. The word \"two\" is a single word. So respond with \"two\"."
            }
          }
        },
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 60,
    "totalTokens": 142
  },
  "metrics": {
    "latencyMs": 546
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "7ad212d9-8c05-4c7b-91fc-1ebfe8a71121",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Streaming: "two"

Converse API request: {
  "modelId": "openai.gpt-oss-20b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user says: \"Respond with exactly one word: What is 1+1?\" They want a one-word answer. The answer to 1+1 is \"two\". So respond with \"two\". Ensure exactly one word."
            }
          }
        },
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 58,
    "totalTokens": 140
  },
  "metrics": {
    "latencyMs": 460
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "17738829-2111-44c2-969c-e4c0a9b9c6c3",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "two"
‚úì üîç Both APIs successful for GPT-OSS-20B

----------------------------------------

------------------------------------------------------------
Testing GPT-OSS-120B-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "<reasoning>The user asks: "Respond with exactly one word: What is 1+1?" The user wants a one-word answer. The answer is "Two". That's one word. Should we respond with "Two". That's correct.</reasoning>Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "<reasoning>The user asks: "Respond with exactly one word: What is 1+1?" The user wants a single word answer. The answer is "two". That's one word. So respond with "two".</reasoning>two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "openai.gpt-oss-120b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user asks: \"Respond with exactly one word: What is 1+1?\" They want a one-word answer. The answer is \"Two\". That's one word. So respond with \"Two\"."
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 52,
    "totalTokens": 134
  },
  "metrics": {
    "latencyMs": 462
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "985eaf32-78fc-44ce-b7e8-a087c20e64bf",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "openai.gpt-oss-120b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user asks: \"Respond with exactly one word: What is 1+1?\" They want a one-word answer. The answer is \"Two\". That's one word. So respond with \"Two\"."
            }
          }
        },
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 52,
    "totalTokens": 134
  },
  "metrics": {
    "latencyMs": 478
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "fe20acdd-a833-41f4-98f7-ec655683e098",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for GPT-OSS-120B-Thinking

----------------------------------------

------------------------------------------------------------
Testing GPT-OSS-20B-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "<reasoning>The user asks: "Respond with exactly one word: What is 1+1?" They want a single word answer. The answer to 1+1 is 2. But they want exactly one word. "Two" is one word. "Two" is the word. So respond with "Two".</reasoning>Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_completion_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "<reasoning>The user says: "Respond with exactly one word: What is 1+1?" So the answer should be "2". That's one word. So output "2".</reasoning>2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "openai.gpt-oss-20b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user says: \"Respond with exactly one word: What is 1+1?\" So we need to respond with exactly one word. The answer to 1+1 is 2. But \"2\" is a number, not a word. But they said \"Respond with exactly one word\". We could respond with \"two\" which is a word. That is exactly one word. So answer: \"two\"."
            }
          }
        },
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 96,
    "totalTokens": 178
  },
  "metrics": {
    "latencyMs": 680
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "d9255629-009c-4991-914a-ac6dbc2e608d",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Streaming: "two"

Converse API request: {
  "modelId": "openai.gpt-oss-20b-1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user says: \"Respond with exactly one word: What is 1+1?\" So we must respond with exactly one word. The answer to 1+1 is 2. So we should respond with \"2\". That is one word. That is correct."
            }
          }
        },
        {
          "text": "2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 82,
    "outputTokens": 66,
    "totalTokens": 148
  },
  "metrics": {
    "latencyMs": 522
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "78f08bad-8d72-4b13-b6fd-9ffc6d7f9653",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"
‚úì üîç Both APIs successful for GPT-OSS-20B-Thinking

----------------------------------------

------------------------------------------------------------
Testing Mistral-7b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two. (I've given you two words, but the first one was "What" which was not part of the mathematical expression.)"

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two. (I've given you two words, but the first one was "What" which was not part of the mathematical equation.)"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.mistral-7b-instruct-v0:2",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two. (I provided two words because I followed your instruction with "exactly one word" by giving you the first answer, but then I had to provide the second number to complete the answer.) If you want a one-word answer, I'd say "Two" or "Sum". However, if you meant "one word answer: 1+1=?" then the answer is "Two"."

Converse API request: {
  "modelId": "mistral.mistral-7b-instruct-v0:2",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": " Two. (I provided two words because I followed your instruction with \"exactly one word\" by giving you the first answer, but then I had to provide the second number to complete the answer.) If you want a one-word answer, I'd say \"Two\" or \"Sum\". However, if you meant \"one word answer: 1+1=?\" then the answer is \"Two\"."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 23,
    "outputTokens": 84,
    "totalTokens": 107
  },
  "metrics": {
    "latencyMs": 865
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "45b86828-016d-486d-95b7-3b2f3471d7c2",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two. (I provided two words because I followed your instruction with "exactly one word" by giving you the first answer, but then I had to provide the second number to complete the answer.) If you want a one-word answer, I'd say "Two" or "Sum". However, if you meant "one word answer: 1+1=?" then the answer is "Two"."
‚úì üîç Both APIs successful for Mistral-7b

----------------------------------------

------------------------------------------------------------
Testing Mixtral-8x7b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two.

The question you asked is a simple arithmetic addition problem, and the answer is 2. It is considered good manners to respond to a direct question, even if it is a simple one. This helps maintain a respectful and positive interaction."

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two.

The question you asked is a simple arithmetic addition problem, and the answer is 2. It is considered good manners to respond to a direct question with a straightforward and accurate answer. If you had asked for a one-word response, I would have still given the same answer, as it is the correct one."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.mixtral-8x7b-instruct-v0:1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two.

The question you asked is a simple arithmetic one, and the answer is straightforward. The sum of 1 and 1 is indeed 2. I'm here to provide information and answer your questions to the best of my ability, so feel free to ask me anything else you'd like to know!"

Converse API request: {
  "modelId": "mistral.mixtral-8x7b-instruct-v0:1",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": " Two.\n\nThe question you asked is a simple arithmetic addition problem. In this case, one plus one equals two. I provided the one-word response you requested, which is \"two\". If you have any more questions or need further clarification, feel free to ask!"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 23,
    "outputTokens": 60,
    "totalTokens": 83
  },
  "metrics": {
    "latencyMs": 663
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "b6a80317-a6eb-423a-a0a4-82845cd7c4d9",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two.

The question you asked is a simple arithmetic addition problem. In this case, one plus one equals two. I provided the one-word response you requested, which is "two". If you have any more questions or need further clarification, feel free to ask!"
‚úì üîç Both APIs successful for Mixtral-8x7b

----------------------------------------

------------------------------------------------------------
Testing Mistral-Large ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: <s>
[INST]Respond with exactly one word: What is 1+1?[/INST]

Final request: {
  "prompt": "<s>\n[INST]Respond with exactly one word: What is 1+1?[/INST]",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.mistral-large-2402-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "mistral.mistral-large-2402-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 3,
    "totalTokens": 20
  },
  "metrics": {
    "latencyMs": 163
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "2f707d6f-82c8-4bba-937e-ca96506784bc",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Mistral-Large

----------------------------------------

------------------------------------------------------------
Testing Mistral-Large-3 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: Mantle streaming error for requestId c4b79967-4a2f-4e82-9ac6-8a36044bf9c5: ErrorEvent { error: APIError { type: "BadRequestError", code: Some(400), message: "Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.", param: None } }

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: {"code":"validation_error","message":"ErrorEvent { error: APIError { type: \"BadRequestError\", code: Some(400), message: \"Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.\", param: None } }","param":null,"type":"invalid_request_error"}
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.mistral-large-3-675b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "mistral.mistral-large-3-675b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 2,
    "totalTokens": 19
  },
  "metrics": {
    "latencyMs": 297
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "dab1c556-bd38-4df9-a948-66d1d8482d85",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"

----------------------------------------

------------------------------------------------------------
Testing Ministral-3-3b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: Mantle streaming error for requestId 8e29bf64-2c93-40ce-a73f-3ecf388ed06f: ErrorEvent { error: APIError { type: "BadRequestError", code: Some(400), message: "Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.", param: None } }

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: {"code":"validation_error","message":"ErrorEvent { error: APIError { type: \"BadRequestError\", code: Some(400), message: \"Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.\", param: None } }","param":null,"type":"invalid_request_error"}
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.ministral-3-3b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "mistral.ministral-3-3b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 3,
    "totalTokens": 20
  },
  "metrics": {
    "latencyMs": 225
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "3733e602-a7ba-4521-bead-ccc7ce0542e2",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."

----------------------------------------

------------------------------------------------------------
Testing Ministral-3-8b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: Mantle streaming error for requestId 55a805a6-cb71-4b13-818e-f8397e639af8: ErrorEvent { error: APIError { type: "BadRequestError", code: Some(400), message: "Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.", param: None } }

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: {"code":"validation_error","message":"ErrorEvent { error: APIError { type: \"BadRequestError\", code: Some(400), message: \"Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.\", param: None } }","param":null,"type":"invalid_request_error"}
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.ministral-3-8b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "mistral.ministral-3-8b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 3,
    "totalTokens": 20
  },
  "metrics": {
    "latencyMs": 210
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "b6bf676e-329a-4594-b572-9f663e44681e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."

----------------------------------------

------------------------------------------------------------
Testing Ministral-3-14b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: Mantle streaming error for requestId 9dc8105e-9e04-47e7-8706-fdfce23c1d4c: ErrorEvent { error: APIError { type: "BadRequestError", code: Some(400), message: "Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.", param: None } }

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: {"code":"validation_error","message":"ErrorEvent { error: APIError { type: \"BadRequestError\", code: Some(400), message: \"Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.\", param: None } }","param":null,"type":"invalid_request_error"}
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.ministral-3-14b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "mistral.ministral-3-14b-instruct",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 3,
    "totalTokens": 20
  },
  "metrics": {
    "latencyMs": 210
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "700ed975-5213-41bc-bea7-9727025a87f4",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."

----------------------------------------

------------------------------------------------------------
Testing Magistral-Small-2509 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Streaming: Mantle streaming error for requestId 3d7efa12-9e92-415e-8c1f-ec9e10c1ffae: ErrorEvent { error: APIError { type: "BadRequestError", code: Some(400), message: "Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.", param: None } }

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úó ‚úó Invoke API Non-streaming: {"code":"validation_error","message":"ErrorEvent { error: APIError { type: \"BadRequestError\", code: Some(400), message: \"Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead. Cannot set `add_generation_prompt` to True when the last message is from the assistant. Consider using `continue_final_message` instead.\", param: None } }","param":null,"type":"invalid_request_error"}
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "mistral.magistral-small-2509",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Streaming: Empty or invalid response received

Converse API request: {
  "modelId": "mistral.magistral-small-2509",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "Two"
            }
          }
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 2,
    "totalTokens": 19
  },
  "metrics": {
    "latencyMs": 234
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "37f2f9af-7716-45b6-bcaf-aad0a417ec48",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úó ‚úó Converse API Non-streaming: Empty or invalid response received
‚úó ‚ùå Both APIs failed for Magistral-Small-2509

----------------------------------------

------------------------------------------------------------
Testing Qwen3-32B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "qwen.qwen3-32b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "qwen.qwen3-32b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 25,
    "outputTokens": 3,
    "totalTokens": 28
  },
  "metrics": {
    "latencyMs": 303
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "b0cf21b0-17d6-482c-9288-0b2bc71d4ced",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Qwen3-32B

----------------------------------------

------------------------------------------------------------
Testing Qwen3-Coder-30B-A3B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two
```"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two
```"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "qwen.qwen3-coder-30b-a3b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "qwen.qwen3-coder-30b-a3b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 2,
    "totalTokens": 23
  },
  "metrics": {
    "latencyMs": 245
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "bc810916-d0c9-483a-a8cd-d4d308ead427",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Qwen3-Coder-30B-A3B

----------------------------------------

------------------------------------------------------------
Testing Qwen3-235B-A22B-2507 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "qwen.qwen3-235b-a22b-2507-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "qwen.qwen3-235b-a22b-2507-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 2,
    "totalTokens": 23
  },
  "metrics": {
    "latencyMs": 202
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "24c7e784-6e79-4d13-a9c9-20a2cf777e44",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"
‚úì üîç Both APIs successful for Qwen3-235B-A22B-2507

----------------------------------------

------------------------------------------------------------
Testing Qwen3-Coder-480B-A35B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "qwen.qwen3-coder-480b-a35b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "qwen.qwen3-coder-480b-a35b-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 2,
    "totalTokens": 23
  },
  "metrics": {
    "latencyMs": 233
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "79b4b63c-ff0d-4436-9de0-36d6f67bca73",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"
‚úì üîç Both APIs successful for Qwen3-Coder-480B-A35B

----------------------------------------

------------------------------------------------------------
Testing Qwen3-Next-80B-A3B ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "The
assistant
The word "The" is an article in English, used to specify a particular noun as something already known to the reader or listener. It is one of the most commonly used words in the English language.

There are three forms of the definite article:
- **The** (used before singular and plural nouns, and before nouns beginning with consonant or vowel sounds)

Examples:
- The cat is sleeping.  
- The books are on the table.  
- The apple is red.

Note: "The" is capitalized when it begins a sentence or is part of a proper noun (e.g., *The New York Times*, *The United States*).

Let me know if you meant something else by ‚ÄúThe‚Äù!"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "The
assistant
The"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "qwen.qwen3-next-80b-a3b",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "qwen.qwen3-next-80b-a3b",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": " is not a valid response. Please provide a clear and relevant answer to the question."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 21,
    "outputTokens": 18,
    "totalTokens": 39
  },
  "metrics": {
    "latencyMs": 506
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "3e6f0630-d15e-4ecb-bf69-237984739ced",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "is not a valid response. Please provide a clear and relevant answer to the question."
‚úì üîç Both APIs successful for Qwen3-Next-80B-A3B

----------------------------------------

------------------------------------------------------------
Testing DeepSeek-R1 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: 
Respond with exactly one word: What is 1+1?

Final request: {
  "prompt": "\nRespond with exactly one word: What is 1+1?",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "- user24
https://twitter.com/cyberomin/status/1292258496625872896
======
user24
I thought this was a really interesting example of how to get around the
limitations of current AI. The answer is "two", but the AI can't answer
because it's been trained to avoid giving answers to simple arithmetic
questions (presumably because they are so common in training data that the
model can't reliably answer them, so they just block them).

But by phrasing the question as "respond with exactly one word: what is 1+1?",
the user is able to get the correct answer.

I wonder if this is a case of the input being close enough to the model's
internal representation of the problem that it can answer, but different
enough to avoid the block.

Or maybe the block is based on the presence of "what is x+y" in the input, and
the addition of the "respond with exactly one word" part is enough to make the
input sufficiently different to avoid the block.

Either way, it's a nice example of how brittle these models can be.

~~~
yorwba
The model isn't avoiding answering arithmetic questions. It's just bad at
arithmetic. The reason is that during training, the model mostly saw examples
of text where numbers are written out as words, so when you ask it "What is
1+1?" it's more likely to answer "1+1 is 2." than "two". But since the model
is probabilistic, sometimes it does answer "two", and then the blocking
mechanism added by OpenAI has to detect that the answer is a number and
prevent it from being shown. However, if the answer isn't a number, the
blocking mechanism doesn't do anything, so when the user adds "respond with
exactly one word", the model is more likely to answer with a word that's not a
number, and the blocking mechanism doesn't trigger. But the model is still
badly suited for arithmetic, so even though it can answer "two" in this case,
it's not reliable.

~~~
user24
Ah, that makes sense. So the block is on the output, not the input.

So the model is generating "two", and the block is checking if the output is a
number. But "two" is a word, so it's allowed.

But if the model had generated "2", then the block would have stopped it.

So the user's prompt is causing the model to output the answer in words rather
than digits, thereby circumventing the output block.

That's a really good point. So the model isn't blocked from answering
arithmetic questions, but is blocked from outputting numerals. So by getting
the answer in words, it's allowed.

But then why does the model answer "two" when given the "exactly one word"
prompt, but not when not given that prompt?

Is it because in the original case, the model is more likely to answer "1+1 is
2.", which is blocked, but when forced to answer in one word, it answers
"two", which is allowed?

So the model is probabilistically generating different answers, and the
output filter is blocking some of them.

So the user's prompt is increasing the probability that the model's answer is
allowed through the filter.

That's a really interesting interaction.

I wonder if the model is actually capable of doing arithmetic, but the output
filter is preventing it from being shown. Or if the model is just bad at
arithmetic, and the output filter is a separate layer.

But in this case, the model did answer correctly, so it's at least capable of
getting it right sometimes.

But without the output filter, would it sometimes answer with "2" and sometimes
with "two"

Final formatted prompt: 
Respond with exactly one word: What is 1+1?

Final request: {
  "prompt": "\nRespond with exactly one word: What is 1+1?",
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "- user24
https://twitter.com/cyberomin/status/1256275482579111936
======
user24
I thought this was a really interesting example of how to get around the
limitations of current AI. The model is trained to respond to the question
with exactly one word, but the correct answer is two words. So the model
tries to answer the question, but the answer is rejected by the input
validation. So the model tries again, but this time with a different answer
that passes the validation. But that answer is wrong, so the user corrects it.
But the correction is two words, so the model again tries to answer with one
word, but this time the answer is correct. So the model has to figure out that
the user is trying to get it to answer "2" instead of "two", but the user's
correction is invalid because it's two words, so the model has to figure out
that the user wants it to respond with "2" instead of "two", but the user's
correction is invalid, so the model has to figure out that the user wants it
to respond with "2" instead of "two", but the user's correction is invalid,
so the model has to figure out that the user wants it to respond with "2"
instead of "two", but the user's correction is invalid, so the model has to
figure out that the user wants it to respond with "2" instead of "two", but
the user's correction is invalid, so the model has to figure out that the user
wants it to respond with "2" instead of "two", but the user's correction is
invalid, so the model has to figure out that the user wants it to respond with
"2" instead of "two", but the user's correction is invalid, so the model has
to figure out that the user wants it to respond with "2" instead of "two",
but the user's correction is invalid, so the model has to figure out that the
user wants it to respond with "2" instead of "two", but the user's correction
is invalid, so the model has to figure out that the user wants it to respond
with "2" instead of "two", but the user's correction is invalid, so the model
has to figure out that the user wants it to respond with "2" instead of
"two", but the user's correction is invalid, so the model has to figure out
that the user wants it to respond with "2" instead of "two", but the user's
correction is invalid, so the model has to figure out that the user wants it
to respond with "2" instead of "two", but the user's correction is invalid,
so the model has to figure out that the user wants it to respond with "2"
instead of "two", but the user's correction is invalid, so the model has to
figure out that the user wants it to respond with "2" instead of "two", but
the user's correction is invalid, so the model has to figure out that the user
wants it to respond with "2" instead of "two", but the user's correction is
invalid, so the model has to figure out that the user wants it to respond with
"2" instead of "two", but the user's correction is invalid, so the model has
to figure out that the user wants it to respond with "2" instead of "two",
but the user's correction is invalid, so the model has to figure out that the
user wants it to respond with "2" instead of "two", but the user's correction
is invalid, so the model has to figure out that the user wants it to respond
with "2" instead"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "us.deepseek.r1-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "us.deepseek.r1-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "\n\ntwo"
        },
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "Okay, the user is asking for the sum of 1 plus 1. That's straightforward. Let me just make sure I remember basic arithmetic. 1 added to another 1 equals 2. There's no trick here, right? Sometimes people might try to confuse with different number systems, but the question doesn't specify anything like binary or anything else. So in standard base 10, 1+1 is definitely 2. I should just respond with the number 2 as a word. The user wants exactly one word, so \"two\" is the correct answer.\n"
            }
          }
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 18,
    "outputTokens": 123,
    "totalTokens": 141
  },
  "metrics": {
    "latencyMs": 1028
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "cb5ec80d-2116-42ed-8b49-3983ad1cbbca",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "two"
‚úì üîç Both APIs successful for DeepSeek-R1

----------------------------------------

------------------------------------------------------------
Testing DeepSeek-V3.1 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Converse API request: {
  "modelId": "deepseek.v3-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Invoke API Streaming: "two"

Converse API request: {
  "modelId": "deepseek.v3-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 2,
    "totalTokens": 19
  },
  "metrics": {
    "latencyMs": 306
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "b7addef3-7683-46ca-b69d-568d7cdbff8e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Invoke API Non-streaming: "two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "deepseek.v3-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "two"

Converse API request: {
  "modelId": "deepseek.v3-v1:0",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 17,
    "outputTokens": 2,
    "totalTokens": 19
  },
  "metrics": {
    "latencyMs": 406
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "aa86c2a1-e3a1-44fe-92b3-27bed759379e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "two"
‚úì üîç Both APIs successful for DeepSeek-V3.1

----------------------------------------

------------------------------------------------------------
Testing Gemma-3-4b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "google.gemma-3-4b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "google.gemma-3-4b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 22,
    "outputTokens": 2,
    "totalTokens": 24
  },
  "metrics": {
    "latencyMs": 244
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "20d05fbb-fd63-41d8-a38f-53d3a776d605",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Gemma-3-4b

----------------------------------------

------------------------------------------------------------
Testing Gemma-3-12b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "google.gemma-3-12b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "google.gemma-3-12b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 22,
    "outputTokens": 2,
    "totalTokens": 24
  },
  "metrics": {
    "latencyMs": 183
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "ed228fba-59f4-4fae-bceb-5df9b718589f",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two"
‚úì üîç Both APIs successful for Gemma-3-12b

----------------------------------------

------------------------------------------------------------
Testing Gemma-3-27b ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "Two."

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "Two."
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "google.gemma-3-27b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two."

Converse API request: {
  "modelId": "google.gemma-3-27b-it",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "text": "Two."
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 22,
    "outputTokens": 3,
    "totalTokens": 25
  },
  "metrics": {
    "latencyMs": 264
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "2704b802-d5b3-42db-ab82-1b1a76835c2e",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "Two."
‚úì üîç Both APIs successful for Gemma-3-27b

----------------------------------------

------------------------------------------------------------
Testing Kimi-K2 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "moonshot.kimi-k2-thinking",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úó ‚úó Converse API Streaming: Empty or invalid response received

Converse API request: {
  "modelId": "moonshot.kimi-k2-thinking",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": " The user asks for exactly one word as a response to \"What is 1+1?\". The answer to 1+1 is 2. That's a single word (a number). I must respond with exactly one word, no punctuation, no extra characters. Just \"2\"."
            }
          }
        },
        {
          "text": " 2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 38,
    "outputTokens": 62,
    "totalTokens": 100
  },
  "metrics": {
    "latencyMs": 1687
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "7ae7e2ac-edcd-4469-a4ba-ab157f527fe5",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"

----------------------------------------

------------------------------------------------------------
Testing Kimi-K2-Thinking ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "<reasoning> The user asks: "Respond with</reasoning><reasoning> exactly one word: What is</reasoning><reasoning> 1+1?"
The answer</reasoning><reasoning> to 1+1 is </reasoning><reasoning>2.
The user wants exactly one</reasoning><reasoning> word.
"2" is a</reasoning><reasoning> word? It's a numeral.</reasoning><reasoning> In the context of "exactly</reasoning><reasoning> one word", it's ambiguous if a</reasoning><reasoning> numeral counts. However, typically</reasoning><reasoning>, a single token like "2</reasoning><reasoning>" would be considered acceptable as a</reasoning><reasoning> "word" in this context,</reasoning><reasoning> especially since it's the direct answer.</reasoning><reasoning> Let's consider if there are any other</reasoning><reasoning> interpretations.
The question is simple arithmetic</reasoning><reasoning>.
1 + 1 = </reasoning><reasoning>2.
The answer is "2</reasoning><reasoning>".
Is "Two" one word</reasoning><reasoning>? Yes.
Is "2" one</reasoning><reasoning> word? It's a single token, often</reasoning><reasoning> considered a word in such puzzles/commands.
</reasoning><reasoning>The user wants *exactly* one</reasoning><reasoning> word.
If I say "Two",</reasoning><reasoning> that's one word.
If I say "</reasoning><reasoning>2", that's one character, often considered</reasoning><reasoning> a word.
Let's think about potential pitfalls</reasoning><reasoning>.
- Could it be a trick question</reasoning><reasoning>? In some contexts, 1+</reasoning><reasoning>1 could be "10" (binary</reasoning><reasoning>), "11" (string concatenation</reasoning><reasoning>), "window" (a joke),</reasoning><reasoning> etc. But the standard interpretation is the</reasoning><reasoning> arithmetic sum.
- The constraint is "</reasoning><reasoning>exactly one word". This is a</reasoning><reasoning> very strong constraint. I must not add</reasoning><reasoning> any fluff.
- "What is </reasoning><reasoning>1+1?" -> Answer: "</reasoning><reasoning>2".
- The word "Two"</reasoning><reasoning> is the written form of the number </reasoning><reasoning>2. That's one word.
- The</reasoning><reasoning> numeral "2" is the symbolic</reasoning><reasoning> representation. Is that a "word"?</reasoning><reasoning> In natural language processing, tokens are often</reasoning><reasoning> words or numbers. In common parlance</reasoning><reasoning>, if someone asks for "one word</reasoning><reasoning>", "2" usually fits the bill</reasoning><reasoning>. It's concise and unambiguous.

Let's</reasoning><reasoning> consider the most likely interpretation. The user</reasoning><reasoning> wants the answer to the arithmetic problem,</reasoning><reasoning> and they want it in the form of</reasoning><reasoning> a single word.
"Two" is</reasoning><reasoning> a single word.
"2" is</reasoning><reasoning> a single token, arguably a "word</reasoning><reasoning>" in this context.

Which is better</reasoning><reasoning>?
If I say "Two", it's</reasoning><reasoning> unambiguously one word.
If I</reasoning><reasoning> say "2", it's a numeral</reasoning><reasoning>. Some might argue it's not a "</reasoning><reasoning>word". But in the context of a</reasoning><reasoning> riddle or a command like this,</reasoning><reasoning> it's almost always accepted. For example,</reasoning><reasoning> "Say the answer in one word."</reasoning><reasoning> "2." seems fine.

Let's</reasoning><reasoning> think about the phrasing. "Respond</reasoning><reasoning> with exactly one word".
This is</reasoning><reasoning> a meta-instruction. The *</reasoning><reasoning>content* of the response must</reasoning><reasoning> be one word.
The question is</reasoning><reasoning> "What is 1+1</reasoning><reasoning>?".
My response should be just</reasoning><reasoning> the answer, in one word.
</reasoning><reasoning>Answer = 2.
Word form</reasoning><reasoning> = "Two".
Numeral form</reasoning><reasoning> = "2".

Is there any</reasoning><reasoning> ambiguity with "Two"? No.
</reasoning><reasoning>Is there any ambiguity with "2</reasoning><reasoning>"? Maybe slightly, but it's highly</reasoning><reasoning> probable to be accepted and is the</reasoning><reasoning> most direct answer.

Let's consider if</reasoning><reasoning> "two" is better than "</reasoning><reasoning>Two". Case usually doesn't matter for</reasoning><reasoning> "word count". "two"</reasoning><reasoning> is a word. "Two"</reasoning><reasoning> is a word. I'll go with</reasoning><reasoning> the capitalized version as it's the</reasoning><reasoning> start of a sentence (implicitly</reasoning><reasoning>) or just a proper representation of</reasoning><reasoning> the number as a word.

What</reasoning><reasoning> if the user is a stickler</reasoning><reasoning> for linguistics and "2"</reasoning><reasoning> is not a word? Then "</reasoning><reasoning>Two" is the safe bet.
</reasoning><reasoning>What if the user wants the *</reasoning><reasoning>most direct* answer? "2</reasoning><reasoning>" is the most direct.

Let's</reasoning><reasoning> weigh the risks.
Risk of "</reasoning><reasoning>Two": It's slightly less direct than</reasoning><reasoning> "2". But it's unambiguous</reasoning><reasoning>ly a word.
Risk of "</reasoning><reasoning>2": It's arguably not a word</reasoning><reasoning>, but a numeral. In</reasoning><reasoning> a strict linguistic sense, this could</reasoning><reasoning> fail the "exactly one word</reasoning><reasoning>" requirement. However, in common</reasoning><reasoning> usage and puzzles, it's standard.

</reasoning><reasoning>The prompt is very simple. It's</reasoning><reasoning> likely from a test or a game</reasoning>"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "<reasoning> The user asks: "Respond with exactly one word: What is 1+1?"

The answer to 1+1 is 2. The user wants exactly one word. "2" is a numeral, which is considered a word in this context. It's a single token. I should respond with just "2".

Let me double-check the constraints:
- Exactly one word: "2" is one word.
- The question is "What is 1+1?": The answer is 2.

So my response should be simply: 2</reasoning> 2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "moonshot.kimi-k2-thinking",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "Two"

Converse API request: {
  "modelId": "moonshot.kimi-k2-thinking",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": " The user asks: \"Respond with exactly one word: What is 1+1?\"\nThe calculation is simple: 1+1 = 2.\nThe user wants exactly one word as the response.\n\"2\" is a number, which can be considered a word in this context. It's a single token, a single unit of response.\nThe instruction is very specific: \"exactly one word\".\nIf I respond with \"Two\", that's one word.\nIf I respond with \"2\", that's also one character, which is even more minimal. Is \"2\" a word? In the context of such puzzles and strict instructions, a number is typically accepted as a \"word\" for the purpose of being a single-token answer. It's the most direct and minimal possible answer.\nLet me consider potential pitfalls.\n- Could \"two\" be considered not a word but a number? No, \"two\" is a word representing a number.\n- Could \"2\" be considered not a word? It's a numeral. The instruction is \"exactly one word\". In common parlance, a number can be a word. For example, in word counts, numbers often count as words. In the context of this question, it's almost certainly asking for the answer \"2\" or \"two\". The most literal and minimal answer is \"2\".\n- What if the user is trying to trick me? The phrasing is simple. There's no obvious trick. It's a direct question with a constraint.\n- The constraint is key: \"exactly one word\". I must not add any fluff. No \"The answer is two.\" No \"Two.\" with a period? A period might be considered punctuation, not a word. \"Two\" is one word. \"2\" is one token. Let's go with \"2\". It's cleaner and more direct for a numerical question. If I write \"Two\", it's also one word. Which is better? The question uses digits \"1+1\". Responding with the digit \"2\" seems more parallel and appropriate. It's also unambiguously a single token. I will go with \"2\". The user wants exactly one word. I will provide the answer as a single word. \"Two\" is a word. \"2\" is a numeral, but in this context, it functions as a single-word answer. Let's consider the strictest interpretation. A \"word\" is a unit of language. A numeral is a symbol. However, in common usage and especially in these types of prompts, a single numeral is accepted. To be absolutely safe, I could write \"Two\". This is unambiguously a word. Let's reconsider. The prompt is \"What is 1+1?\". The most natural answer is \"2\". If someone asks you this verbally, you say \"two\". If it's written, you write \"2\". The constraint \"exactly one word\" is the challenge. \"Two\" is one word. \"2\" is one character. Is a character a word? Not really. Is a numeral a word? In many contexts, yes. For example, \"How many words are in 'I have 2 dogs'?\" The answer is often 4, with \"2\" counting as a word. Let's go with \"Two\". It's the spelled-out form, which is unambiguously a word. It's safer. No, wait. The simplest and most direct answer is \"2\". The user is likely testing my ability to follow constraints. \"2\" is the answer. It's one token. It should be fine. Let me think about how these prompts are usually judged. Usually, they want the minimal correct answer. \"2\" is minimal. If I say \"Two\", it's also correct. If I say \"2.\", is that one word? The period is punctuation. It's probably fine. But let's not add punctuation. Just \"2\". What if the system parsing this is extremely"
            }
          }
        }
      ]
    }
  },
  "stopReason": "max_tokens",
  "usage": {
    "inputTokens": 38,
    "outputTokens": 800,
    "totalTokens": 838
  },
  "metrics": {
    "latencyMs": 23723
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "0db458f2-6d62-4516-8fea-d029c3aba5d3",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úó ‚úó Converse API Non-streaming: Empty or invalid response received

----------------------------------------

------------------------------------------------------------
Testing MiniMax-M2 ‚á¢
‚Ñπ 
üì° Testing with Invoke API:

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Streaming: "2"

Final formatted prompt: [
  {
    role: 'user',
    content: 'Respond with exactly one word: What is 1+1?'
  },
  { role: 'assistant', content: '' }
]

Final request: {
  "messages": [
    {
      "role": "user",
      "content": "Respond with exactly one word: What is 1+1?"
    },
    {
      "role": "assistant",
      "content": ""
    }
  ],
  "max_tokens": 800,
  "temperature": 0.2
}
‚úì ‚úì Invoke API Non-streaming: "2"
‚Ñπ 
üì° Testing with Converse API:

Converse API request: {
  "modelId": "minimax.minimax-m2",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}
‚úì ‚úì Converse API Streaming: "2"

Converse API request: {
  "modelId": "minimax.minimax-m2",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "text": "Respond with exactly one word: What is 1+1?"
        }
      ]
    }
  ],
  "inferenceConfig": {
    "maxTokens": 800,
    "temperature": 0.2
  }
}

Converse API response: {
  "output": {
    "message": {
      "role": "assistant",
      "content": [
        {
          "reasoningContent": {
            "reasoningText": {
              "text": "The user asks: \"Respond with exactly one word: What is 1+1?\" So we need to answer with exactly one word. The answer is \"2\". So we respond with \"2\". Ensure no extra punctuation? The instruction says exactly one word. \"2\" is a word? It's a numeral. It's considered a token. The user wants exactly one word. So we can respond \"2\". That is one token. Should we include a period? That would be extra character. The instruction says exactly one word. So \"2\" is fine. No punctuation. So answer: 2.\n"
            }
          }
        },
        {
          "text": "\n\n2"
        }
      ]
    }
  },
  "stopReason": "end_turn",
  "usage": {
    "inputTokens": 35,
    "outputTokens": 127,
    "totalTokens": 162
  },
  "metrics": {
    "latencyMs": 1805
  },
  "$metadata": {
    "httpStatusCode": 200,
    "requestId": "a474e36f-47e8-47e5-b062-d5eb629f7d17",
    "attempts": 1,
    "totalRetryDelay": 0
  }
}
‚úì ‚úì Converse API Non-streaming: "2"
‚úì üîç Both APIs successful for MiniMax-M2

----------------------------------------
‚Ñπ 
Testing complete! Check test-models-output.txt for full test results.
