AWS Bedrock Converse API Test Results
Test started at: 2025-11-19T04:33:23.893Z
============================================================

Starting Converse API tests with 9 representative models...
Testing: Invoke API vs Converse API comparison


============================================================
Testing Claude-4-1-Opus
============================================================

Comparing STREAMING responses for Claude-4-1-Opus:
  Invoke API (3855ms): "The capital of France is Paris...."
  Converse API (3210ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-4-1-Opus:
  Invoke API (3450ms): "The capital of France is Paris...."
  Converse API (3746ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-4-1-Opus:
  Converse API response: "Ahoy there, matey! I be doin' fine as rum on a calm sea, I am! The winds be fair and me spirits high..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-4-1-Opus:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-4-1-Opus

============================================================
Testing Claude-3-5-Sonnet-v2
============================================================

Comparing STREAMING responses for Claude-3-5-Sonnet-v2:
  Invoke API (666ms): "Paris is the capital of France...."
  Converse API (577ms): "Paris is the capital of France...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-3-5-Sonnet-v2:
  Invoke API (609ms): "Paris is the capital of France...."
  Converse API (562ms): "Paris is the capital of France...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-3-5-Sonnet-v2:
  Converse API response: "Yarr, ahoy there matey! I be doin' right fine, with fair winds and followin' seas! Me timbers be shi..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-3-5-Sonnet-v2:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-3-5-Sonnet-v2

============================================================
Testing Claude-3-Haiku
============================================================

Comparing STREAMING responses for Claude-3-Haiku:
  Invoke API (367ms): "The capital of France is Paris...."
  Converse API (872ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-3-Haiku:
  Invoke API (417ms): "The capital of France is Paris...."
  Converse API (330ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-3-Haiku:
  Converse API response: "Ahoy, matey! Aye, I be feelin' as jolly as a swashbuckler with a chest o' gold. The high seas be tre..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-3-Haiku:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-3-Haiku

============================================================
Testing Nova-Pro
============================================================

Comparing STREAMING responses for Nova-Pro:
  Invoke API (954ms): "1. **Identify the country in question**:  The question asks for the capital of France.

2. **Recall ..."
  Converse API (335ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Pro:
  Invoke API (655ms): "1. **Identify the country in question**:  The question asks for the capital of France.

2. **Recall ..."
  Converse API (364ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Pro:
  Converse API response: "Ahoy, matey! I be doin' fine, thank ye fer askin'. The sea be callin' me name, and me heart be as li..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Pro:
  Converse API result: "It looks like you've started counting from 1 to 5. Let me continue the sequence for you:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Pro

============================================================
Testing Nova-Lite
============================================================

Comparing STREAMING responses for Nova-Lite:
  Invoke API (858ms): "1. Identify the country in question: France.
2. Recall the capital of France, which is a well-known ..."
  Converse API (423ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Lite:
  Invoke API (564ms): "1. Identify the country in question: France.
2. Recall the capital of France, which is a well-known ..."
  Converse API (314ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Lite:
  Converse API response: "Ahoy there! How be ye holdin' up, matey? The sea be treatin' us well today, but the wind be as fierc..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Lite:
  Converse API result: "Certainly! Here is the sequence from 1 to 10, separated by commas:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Lite

============================================================
Testing Nova-Micro
============================================================

Comparing STREAMING responses for Nova-Micro:
  Invoke API (282ms): "The capital of France is Paris...."
  Converse API (282ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Micro:
  Invoke API (286ms): "The capital of France is Paris...."
  Converse API (289ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Micro:
  Converse API response: "Arrr, 'ello there, matey! I be fair to middlin', thank ye fer askin'. How be the tides treatin' ye? ..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Micro:
  Converse API result: "Sure, here is the count from 1 to 10, separated by commas:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Micro

============================================================
Testing Llama-3-3-70b
============================================================

Comparing STREAMING responses for Llama-3-3-70b:
  Invoke API (387ms): "The capital of France is Paris...."
  Converse API (349ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Llama-3-3-70b:
  Invoke API (298ms): "The capital of France is Paris...."
  Converse API (287ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Llama-3-3-70b:
  Converse API response: "Yer lookin' fer a chat, eh? Well, matey, I be feelin' ship-shape, thank ye fer askin'! Me day be goi..."
  ✓ System prompt was correctly applied

✓ All tests passed for Llama-3-3-70b

============================================================
Testing Llama-3-2-90b
============================================================

Comparing STREAMING responses for Llama-3-2-90b:
  Invoke API (394ms): "The capital of France is Paris...."
  Converse API (354ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Llama-3-2-90b:
  Invoke API (347ms): "The capital of France is Paris...."
  Converse API (408ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Llama-3-2-90b:
  Converse API response: "Yer lookin' fer a chat, eh? Well, matey, I be doin' just fine, thank ye fer askin'. Me sea legs be s..."
  ✓ System prompt was correctly applied

✓ All tests passed for Llama-3-2-90b

============================================================
Testing Mistral-7b
============================================================

Comparing STREAMING responses for Mistral-7b:
  Invoke API (216ms): "The capital city of France is Paris...."
  Converse API (254ms): "The capital city of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Mistral-7b:
  Invoke API (231ms): "The capital city of France is Paris...."
  Converse API (223ms): "The capital city of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Mistral-7b:
  Converse API response: " Arr, shiver me timbers! That be a fine question, landlubber! I be feelin' as fit as a fiddle and re..."
  ✓ System prompt was correctly applied

Testing stop sequences for Mistral-7b:
  Converse API result: "I'd be happy to help you with that! Here's the sequence you requested: 1, 2, 3, 4, 5. Let me know if you need any assistance with anything else. Have a great day!"
  Invoke API result: "I'd be happy to help you with that! Here's the sequence you requested: 1, 2, 3, 4, 5. Let me know if you need any assistance with anything else. Have a great day!"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Mistral-7b

============================================================
TEST SUMMARY
============================================================
Models tested: 9
Passed: 9
Failed: 0
