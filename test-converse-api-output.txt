AWS Bedrock Converse API Test Results
Test started at: 2025-10-16T21:56:28.137Z
============================================================

Starting Converse API tests with 9 representative models...
Testing: Invoke API vs Converse API comparison


============================================================
Testing Claude-4-1-Opus
============================================================

Comparing STREAMING responses for Claude-4-1-Opus:
  Invoke API (3792ms): "The capital of France is Paris...."
  Converse API (4565ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-4-1-Opus:
  Invoke API (3912ms): "The capital of France is Paris...."
  Converse API (3582ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-4-1-Opus:
  Converse API response: "Ahoy there, matey! I be doin' fine as rum on a calm sea, thank ye fer askin'! Been sailin' the digit..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-4-1-Opus:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-4-1-Opus

============================================================
Testing Claude-3-5-Sonnet-v2
============================================================

Comparing STREAMING responses for Claude-3-5-Sonnet-v2:
  Invoke API (717ms): "Paris is the capital of France...."
  Converse API (895ms): "Paris is the capital of France...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-3-5-Sonnet-v2:
  Invoke API (1299ms): "Paris is the capital of France...."
  Converse API (612ms): "Paris is the capital of France...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-3-5-Sonnet-v2:
  Converse API response: "Yarr, ahoy there matey! I be right as rain and shipshape today! Me timbers be shiverin' with excitem..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-3-5-Sonnet-v2:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-3-5-Sonnet-v2

============================================================
Testing Claude-3-Haiku
============================================================

Comparing STREAMING responses for Claude-3-Haiku:
  Invoke API (383ms): "The capital of France is Paris...."
  Converse API (390ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Claude-3-Haiku:
  Invoke API (378ms): "The capital of France is Paris...."
  Converse API (424ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Claude-3-Haiku:
  Converse API response: "Ahoy, me hearty! Yer scurvy pirate be doin' just fine, thank ye kindly. The sea be treatin' me well,..."
  ✓ System prompt was correctly applied

Testing stop sequences for Claude-3-Haiku:
  Converse API result: "1, 2, 3, 4, 5,"
  Invoke API result: "1, 2, 3, 4, 5,"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Claude-3-Haiku

============================================================
Testing Nova-Pro
============================================================

Comparing STREAMING responses for Nova-Pro:
  Invoke API (620ms): "1. **Identify the country in question**:  The question asks for the capital of France.

2. **Recall ..."
  Converse API (309ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Pro:
  Invoke API (596ms): "1. **Identify the country in question**:  The question asks for the capital of France.

2. **Recall ..."
  Converse API (331ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Pro:
  Converse API response: "Ahoy, matey! I be doin' fine, thank ye fer askin'. The sea be callin' an' me heart be light. What be..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Pro:
  Converse API result: "It looks like you've started counting from 1 to 5. Let me continue the sequence for you:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Pro

============================================================
Testing Nova-Lite
============================================================

Comparing STREAMING responses for Nova-Lite:
  Invoke API (518ms): "1. Identify the country in question: France.
2. Recall the capital of France, which is a well-known ..."
  Converse API (269ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Lite:
  Invoke API (519ms): "1. Identify the country in question: France.
2. Recall the capital of France, which is a well-known ..."
  Converse API (262ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Lite:
  Converse API response: "Ahoy there! How be ye holdin' up, matey? The sea be treatin' us well today, but the wind be as fickl..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Lite:
  Converse API result: "Certainly! Here is the sequence from 1 to 10, separated by commas:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Lite

============================================================
Testing Nova-Micro
============================================================

Comparing STREAMING responses for Nova-Micro:
  Invoke API (249ms): "The capital of France is Paris...."
  Converse API (238ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Nova-Micro:
  Invoke API (251ms): "The capital of France is Paris...."
  Converse API (258ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Nova-Micro:
  Converse API response: "Arrr, 'ello there, matey! I be fair to middlin', thank ye fer askin'. How be the tides treatin' ye? ..."
  ✓ System prompt was correctly applied

Testing stop sequences for Nova-Micro:
  Converse API result: "Sure, here is the count from 1 to 10, separated by commas:

1, 2, 3, 4, 5, 6"
  Invoke API result: "1, 2, 3, 4, 5, 6"
  ⚠ Converse API did not stop correctly
  ⚠ Invoke API did not stop correctly

✓ All tests passed for Nova-Micro

============================================================
Testing Llama-3-3-70b
============================================================

Comparing STREAMING responses for Llama-3-3-70b:
  Invoke API (358ms): "The capital of France is Paris...."
  Converse API (364ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Llama-3-3-70b:
  Invoke API (350ms): "The capital of France is Paris...."
  Converse API (290ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Llama-3-3-70b:
  Converse API response: "Yer lookin' fer a chat, eh? Alright then, matey! I be doin' swell, thank ye fer askin'. Me sea legs ..."
  ✓ System prompt was correctly applied

✓ All tests passed for Llama-3-3-70b

============================================================
Testing Llama-3-2-90b
============================================================

Comparing STREAMING responses for Llama-3-2-90b:
  Invoke API (341ms): "The capital of France is Paris...."
  Converse API (336ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Llama-3-2-90b:
  Invoke API (373ms): "The capital of France is Paris...."
  Converse API (311ms): "The capital of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Llama-3-2-90b:
  Converse API response: "Yer lookin' fer a chat, eh? Well, matey, I be feelin' as fit as a sea dog on a sunny day. Me grog be..."
  ✓ System prompt was correctly applied

✓ All tests passed for Llama-3-2-90b

============================================================
Testing Mistral-7b
============================================================

Comparing STREAMING responses for Mistral-7b:
  Invoke API (220ms): "The capital city of France is Paris...."
  Converse API (253ms): "The capital city of France is Paris...."
  ✓ Both APIs returned valid responses

Comparing NON-STREAMING responses for Mistral-7b:
  Invoke API (216ms): "The capital city of France is Paris...."
  Converse API (201ms): "The capital city of France is Paris...."
  ✓ Both APIs returned valid responses

Testing system prompt handling for Mistral-7b:
  Converse API response: " Ahoy there, landlubber! Me hearty self bein' as fit as a fiddle, an' me spirits be high as a galleo..."
  ✓ System prompt was correctly applied

Testing stop sequences for Mistral-7b:
  Converse API result: "I'd be happy to help you with that! Here's the sequence you requested: 1, 2, 3, 4, 5. Let me know if you need any assistance with anything else. Have a great day!"
  Invoke API result: "I'd be happy to help you with that! Here's the sequence you requested: 1, 2, 3, 4, 5. Let me know if you need any assistance with anything else. Have a great day!"
  ✓ Both APIs correctly applied stop sequences

✓ All tests passed for Mistral-7b

============================================================
TEST SUMMARY
============================================================
Models tested: 9
Passed: 9
Failed: 0
